{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d966a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "from datetime import timedelta\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def simulate_central_scenario(seed=1234):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 1. Create underwriting dates from 2016-01-01 to 2017-12-31\n",
    "    dt_policydates = pd.DataFrame({\n",
    "        \"date_UW\": pd.date_range(\"2016-01-01\", \"2017-12-31\", freq=\"D\")\n",
    "    })\n",
    "\n",
    "    # 2. Simulate daily policy counts with Poisson distribution\n",
    "    dt_policydates[\"policycount\"] = np.random.poisson(700, size=len(dt_policydates))\n",
    "    dt_policydates[\"date_lapse\"] = dt_policydates[\"date_UW\"] + pd.DateOffset(years=1)\n",
    "    dt_policydates[\"expodays\"] = (dt_policydates[\"date_lapse\"] - dt_policydates[\"date_UW\"]).dt.days\n",
    "    dt_policydates[\"pol_prefix\"] = (\n",
    "        dt_policydates[\"date_UW\"].dt.year * 10000 +\n",
    "        dt_policydates[\"date_UW\"].dt.month * 100 +\n",
    "        dt_policydates[\"date_UW\"].dt.day\n",
    "    )\n",
    "\n",
    "    # 3. Define coverage splits\n",
    "    dt_policydates[\"Cover_B\"] = (dt_policydates[\"policycount\"] * 0.25).round().astype(int)\n",
    "    dt_policydates[\"Cover_BO\"] = (dt_policydates[\"policycount\"] * 0.45).round().astype(int)\n",
    "    dt_policydates[\"Cover_BOT\"] = dt_policydates[\"policycount\"] - dt_policydates[\"Cover_B\"] - dt_policydates[\"Cover_BO\"]\n",
    "\n",
    "    # 4. Expand rows by policycount\n",
    "    dt_policy = dt_policydates.loc[\n",
    "        dt_policydates.index.repeat(dt_policydates[\"policycount\"])\n",
    "    ][[\"date_UW\", \"pol_prefix\"]].copy()\n",
    "    dt_policy[\"pol_seq\"] = dt_policy.groupby(\"pol_prefix\").cumcount() + 1\n",
    "\n",
    "    # FIX: Use int64 to avoid overflow for pol_number\n",
    "    dt_policy[\"pol_number\"] = (dt_policy[\"pol_prefix\"].astype(np.int64) * 10000 + dt_policy[\"pol_seq\"]).astype(str)\n",
    "\n",
    "    # 5. Merge coverage data\n",
    "    dt_policydates.drop(columns=\"pol_prefix\", inplace=True)\n",
    "    dt_policy = pd.merge(dt_policy, dt_policydates, on=\"date_UW\", how=\"left\")\n",
    "\n",
    "    # 6. Assign cover type\n",
    "    dt_policy[\"Cover\"] = \"BO\"\n",
    "    dt_policy.loc[dt_policy[\"pol_seq\"] <= (dt_policy[\"policycount\"] - dt_policy[\"Cover_BO\"]), \"Cover\"] = \"BOT\"\n",
    "    dt_policy.loc[dt_policy[\"pol_seq\"] <= dt_policy[\"Cover_B\"], \"Cover\"] = \"B\"\n",
    "\n",
    "    # 7. Assign brand and base price\n",
    "    brand_pattern = np.tile(np.repeat([1, 2, 3, 4], [9, 6, 3, 2]), int(np.ceil(len(dt_policy)/20)))[:len(dt_policy)]\n",
    "    base_price_pattern = np.tile(np.repeat([600, 550, 300, 150], [9, 6, 3, 2]), int(np.ceil(len(dt_policy)/20)))[:len(dt_policy)]\n",
    "    dt_policy[\"Brand\"] = brand_pattern\n",
    "    dt_policy[\"Base_Price\"] = base_price_pattern\n",
    "\n",
    "    # 8. Model and multipliers\n",
    "    dt_policy[\"Model\"] = 0\n",
    "    dt_policy[\"Model_mult\"] = 1.0\n",
    "    model_vals = np.repeat([3, 2, 1, 0], [10, 7, 2, 1])\n",
    "    model_mults = np.repeat([1.15**3, 1.15**2, 1.15, 1.0], [10, 7, 2, 1])\n",
    "\n",
    "    for brand in dt_policy[\"Brand\"].unique():\n",
    "        mask = dt_policy[\"Brand\"] == brand\n",
    "        n = mask.sum()\n",
    "        dt_policy.loc[mask, \"Model\"] = np.tile(model_vals, int(np.ceil(n/len(model_vals))))[:n]\n",
    "        dt_policy.loc[mask, \"Model_mult\"] = np.tile(model_mults, int(np.ceil(n/len(model_mults))))[:n]\n",
    "\n",
    "    dt_policy[\"Price\"] = np.ceil(dt_policy[\"Base_Price\"] * dt_policy[\"Model_mult\"]).astype(int)\n",
    "\n",
    "    # 9. Final columns\n",
    "    dt_policy = dt_policy[[\"pol_number\", \"date_UW\", \"date_lapse\", \"Cover\", \"Brand\", \"Model\", \"Price\"]]\n",
    "\n",
    "    # --- Simulate Claims ---\n",
    "    # Breakage (15% of all)\n",
    "    claim_idx = np.random.choice(dt_policy.index, size=int(0.15 * len(dt_policy)), replace=False)\n",
    "    dt_claim = pd.DataFrame({\n",
    "        \"pol_number\": dt_policy.loc[claim_idx, \"pol_number\"].values,\n",
    "        \"claim_type\": \"B\",\n",
    "        \"claim_count\": 1,\n",
    "        \"claim_sev\": beta.rvs(2, 5, size=len(claim_idx))\n",
    "    })\n",
    "\n",
    "    # Oxidation (5% of BO and BOT)\n",
    "    oxidation_idx = dt_policy[dt_policy[\"Cover\"] != \"B\"].index\n",
    "    ox_claim_idx = np.random.choice(oxidation_idx, size=int(0.05 * len(oxidation_idx)), replace=False)\n",
    "    ox_claims = pd.DataFrame({\n",
    "        \"pol_number\": dt_policy.loc[ox_claim_idx, \"pol_number\"].values,\n",
    "        \"claim_type\": \"O\",\n",
    "        \"claim_count\": 1,\n",
    "        \"claim_sev\": beta.rvs(5, 3, size=len(ox_claim_idx))\n",
    "    })\n",
    "    dt_claim = pd.concat([dt_claim, ox_claims], ignore_index=True)\n",
    "\n",
    "    # Theft (5% * severity multiplier by Model)\n",
    "    for m in range(4):\n",
    "        theft_idx = dt_policy[(dt_policy[\"Cover\"] == \"BOT\") & (dt_policy[\"Model\"] == m)].index\n",
    "        count = int(0.05 * (1 + m) * len(theft_idx))\n",
    "        sampled = np.random.choice(theft_idx, size=min(count, len(theft_idx)), replace=False)\n",
    "        theft_claims = pd.DataFrame({\n",
    "            \"pol_number\": dt_policy.loc[sampled, \"pol_number\"].values,\n",
    "            \"claim_type\": \"T\",\n",
    "            \"claim_count\": 1,\n",
    "            \"claim_sev\": beta.rvs(5, 0.5, size=len(sampled))\n",
    "        })\n",
    "        dt_claim = pd.concat([dt_claim, theft_claims], ignore_index=True)\n",
    "\n",
    "    # --- Join policy info ---\n",
    "    dt_claim = pd.merge(dt_claim, dt_policy[[\"pol_number\", \"date_UW\", \"Price\", \"Brand\"]], on=\"pol_number\", how=\"left\")\n",
    "\n",
    "    # --- Simulate dates ---\n",
    "    dt_claim[\"date_lapse\"] = dt_claim[\"date_UW\"] + pd.DateOffset(years=1)\n",
    "    dt_claim[\"expodays\"] = (dt_claim[\"date_lapse\"] - dt_claim[\"date_UW\"]).dt.days\n",
    "    dt_claim[\"occ_delay_days\"] = (dt_claim[\"expodays\"] * np.random.uniform(0, 1, len(dt_claim))).astype(int)\n",
    "    dt_claim[\"delay_report\"] = (365 * beta.rvs(0.4, 10, size=len(dt_claim))).astype(int)\n",
    "    dt_claim[\"delay_pay\"] = (10 + 40 * beta.rvs(7, 7, size=len(dt_claim))).astype(int)\n",
    "\n",
    "    dt_claim[\"date_occur\"] = dt_claim[\"date_UW\"] + pd.to_timedelta(dt_claim[\"occ_delay_days\"], unit=\"D\")\n",
    "    dt_claim[\"date_report\"] = dt_claim[\"date_occur\"] + pd.to_timedelta(dt_claim[\"delay_report\"], unit=\"D\")\n",
    "    dt_claim[\"date_pay\"] = dt_claim[\"date_report\"] + pd.to_timedelta(dt_claim[\"delay_pay\"], unit=\"D\")\n",
    "    dt_claim[\"claim_cost\"] = (dt_claim[\"Price\"] * dt_claim[\"claim_sev\"]).round().astype(int)\n",
    "\n",
    "    # --- Create claim key and remove duplicates ---\n",
    "    dt_claim[\"clm_prefix\"] = (\n",
    "        dt_claim[\"date_occur\"].dt.year * 10000 +\n",
    "        dt_claim[\"date_occur\"].dt.month * 100 +\n",
    "        dt_claim[\"date_occur\"].dt.day\n",
    "    )\n",
    "    dt_claim[\"clm_seq\"] = dt_claim.groupby(\"clm_prefix\").cumcount() + 1\n",
    "\n",
    "    # FIX: Use int64 to avoid overflow for clm_number\n",
    "    dt_claim[\"clm_number\"] = (dt_claim[\"clm_prefix\"].astype(np.int64) * 10000 + dt_claim[\"clm_seq\"]).astype(str)\n",
    "\n",
    "    dt_claim[\"polclm_seq\"] = dt_claim.groupby(\"pol_number\").cumcount() + 1\n",
    "    dt_claim = dt_claim[dt_claim[\"polclm_seq\"] == 1]\n",
    "\n",
    "    # --- Final claim columns ---\n",
    "    dt_claim = dt_claim[[\n",
    "        \"clm_number\", \"pol_number\", \"claim_type\", \"claim_count\", \"claim_sev\",\n",
    "        \"date_occur\", \"date_report\", \"date_pay\", \"claim_cost\"\n",
    "    ]]\n",
    "\n",
    "    return dt_policy.reset_index(drop=True), dt_claim.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dd5b2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pol_number</th>\n",
       "      <th>date_UW</th>\n",
       "      <th>date_lapse</th>\n",
       "      <th>Cover</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>201601010001</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201601010002</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201601010003</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201601010004</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201601010005</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>clm_number</th>\n",
       "      <th>pol_number</th>\n",
       "      <th>claim_type</th>\n",
       "      <th>claim_count</th>\n",
       "      <th>claim_sev</th>\n",
       "      <th>date_occur</th>\n",
       "      <th>date_report</th>\n",
       "      <th>date_pay</th>\n",
       "      <th>claim_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>201801180001</td>\n",
       "      <td>201707030353</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.639180</td>\n",
       "      <td>2018-01-18</td>\n",
       "      <td>2018-02-11</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201612260001</td>\n",
       "      <td>201610100547</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.260456</td>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201701200001</td>\n",
       "      <td>201604150398</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070113</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>2017-02-16</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201707150001</td>\n",
       "      <td>201608220393</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150239</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201804100001</td>\n",
       "      <td>201706270312</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371893</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>2018-04-10</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt_policy, dt_claim = simulate_central_scenario(seed=1234)\n",
    "\n",
    "# Show top rows\n",
    "display(HTML(dt_policy.head().to_html(index=False)))\n",
    "display(HTML(dt_claim.head().to_html(index=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd8f3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_claim.to_csv(\"aa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b23f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09bc9b90-80a5-4393-82d1-0f1613af8491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76643f74-0e0d-47fe-8279-bd08d67bf741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_central_scenario(seed=1234):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Policy data\n",
    "    date_range = pd.date_range(start=\"2016-01-01\", end=\"2017-12-31\")\n",
    "    policy_data = []\n",
    "\n",
    "    for date in date_range:\n",
    "        count = np.random.poisson(700)\n",
    "        for i in range(count):\n",
    "            policy = {\n",
    "                \"date_UW\": date,\n",
    "                \"date_lapse\": date + relativedelta(years=1),\n",
    "                \"pol_prefix\": int(date.year * 10000 + date.month * 100 + date.day)\n",
    "            }\n",
    "            policy_data.append(policy)\n",
    "\n",
    "    dt_policy = pd.DataFrame(policy_data)\n",
    "    dt_policy[\"pol_seq\"] = dt_policy.groupby(\"pol_prefix\").cumcount() + 1\n",
    "    dt_policy[\"pol_number\"] = (dt_policy[\"pol_prefix\"] * 10000 + dt_policy[\"pol_seq\"]).astype(str)\n",
    "\n",
    "    # Coverage assignment\n",
    "    grouped = dt_policy.groupby(\"date_UW\")[\"pol_number\"].count().reset_index(name=\"policycount\")\n",
    "    grouped[\"Cover_B\"] = (grouped[\"policycount\"] * 0.25).round().astype(int)\n",
    "    grouped[\"Cover_BO\"] = (grouped[\"policycount\"] * 0.45).round().astype(int)\n",
    "    grouped[\"Cover_BOT\"] = grouped[\"policycount\"] - grouped[\"Cover_B\"] - grouped[\"Cover_BO\"]\n",
    "    dt_policy = dt_policy.merge(grouped, on=\"date_UW\", how=\"left\")\n",
    "\n",
    "    dt_policy[\"Cover\"] = \"BO\"\n",
    "    dt_policy[\"rank\"] = dt_policy.groupby(\"date_UW\").cumcount() + 1\n",
    "    dt_policy.loc[dt_policy[\"rank\"] <= dt_policy[\"Cover_BOT\"], \"Cover\"] = \"BOT\"\n",
    "    dt_policy.loc[dt_policy[\"rank\"] <= dt_policy[\"Cover_B\"], \"Cover\"] = \"B\"\n",
    "\n",
    "    # Assign brand/model/price\n",
    "    brands = [1]*9 + [2]*6 + [3]*3 + [4]*2\n",
    "    dt_policy[\"Brand\"] = np.resize(brands, len(dt_policy))\n",
    "    base_prices = {1: 600, 2: 550, 3: 300, 4: 150}\n",
    "    dt_policy[\"Base_Price\"] = dt_policy[\"Brand\"].map(base_prices)\n",
    "\n",
    "    model_seq = [3]*10 + [2]*7 + [1]*2 + [0]*1\n",
    "    model_mult = {3: 1.15**3, 2: 1.15**2, 1: 1.15**1, 0: 1.0}\n",
    "    dt_policy[\"Model\"] = np.resize(model_seq, len(dt_policy))\n",
    "    dt_policy[\"Model_mult\"] = dt_policy[\"Model\"].map(model_mult)\n",
    "    dt_policy[\"Price\"] = np.ceil(dt_policy[\"Base_Price\"] * dt_policy[\"Model_mult\"]).astype(int)\n",
    "\n",
    "    dt_policy = dt_policy[[\"pol_number\", \"date_UW\", \"date_lapse\", \"Cover\", \"Brand\", \"Model\", \"Price\"]]\n",
    "\n",
    "    # Claim data\n",
    "    claim_indices_B = np.random.choice(dt_policy.index, size=int(0.15 * len(dt_policy)), replace=False)\n",
    "    dt_claim = dt_policy.loc[claim_indices_B, [\"pol_number\"]].copy()\n",
    "    dt_claim[\"claim_type\"] = \"B\"\n",
    "    dt_claim[\"claim_count\"] = 1\n",
    "    dt_claim[\"claim_sev\"] = np.random.beta(2, 5, size=len(dt_claim))\n",
    "\n",
    "    indices_O = dt_policy[dt_policy[\"Cover\"].isin([\"BO\", \"BOT\"])].index\n",
    "    claim_indices_O = np.random.choice(indices_O, size=int(0.05 * len(indices_O)), replace=False)\n",
    "    dt_O = dt_policy.loc[claim_indices_O, [\"pol_number\"]].copy()\n",
    "    dt_O[\"claim_type\"] = \"O\"\n",
    "    dt_O[\"claim_count\"] = 1\n",
    "    dt_O[\"claim_sev\"] = np.random.beta(5, 3, size=len(dt_O))\n",
    "    dt_claim = pd.concat([dt_claim, dt_O])\n",
    "\n",
    "    for m in [0, 1, 2, 3]:\n",
    "        subset = dt_policy[(dt_policy[\"Cover\"] == \"BOT\") & (dt_policy[\"Model\"] == m)]\n",
    "        n = int(0.05 * (1 + m) * len(subset))\n",
    "        claim_indices_T = np.random.choice(subset.index, size=n, replace=False)\n",
    "        dt_T = dt_policy.loc[claim_indices_T, [\"pol_number\"]].copy()\n",
    "        dt_T[\"claim_type\"] = \"T\"\n",
    "        dt_T[\"claim_count\"] = 1\n",
    "        dt_T[\"claim_sev\"] = np.random.beta(5, 0.5, size=len(dt_T))\n",
    "        dt_claim = pd.concat([dt_claim, dt_T])\n",
    "\n",
    "    dt_claim = dt_claim.merge(dt_policy[[\"pol_number\", \"date_UW\", \"Price\", \"Brand\"]], on=\"pol_number\", how=\"left\")\n",
    "    dt_claim[\"date_lapse\"] = dt_claim[\"date_UW\"] + pd.DateOffset(years=1)\n",
    "    dt_claim[\"expodays\"] = (dt_claim[\"date_lapse\"] - dt_claim[\"date_UW\"]).dt.days\n",
    "    dt_claim[\"occ_delay_days\"] = (dt_claim[\"expodays\"] * np.random.rand(len(dt_claim))).astype(int)\n",
    "    dt_claim[\"delay_report\"] = np.floor(365 * np.random.beta(.4, 10, size=len(dt_claim))).astype(int)\n",
    "    dt_claim[\"delay_pay\"] = np.floor(10 + 40 * np.random.beta(7, 7, size=len(dt_claim))).astype(int)\n",
    "\n",
    "    dt_claim[\"date_occur\"] = dt_claim[\"date_UW\"] + pd.to_timedelta(dt_claim[\"occ_delay_days\"], unit='D')\n",
    "    dt_claim[\"date_report\"] = dt_claim[\"date_occur\"] + pd.to_timedelta(dt_claim[\"delay_report\"], unit='D')\n",
    "    dt_claim[\"date_pay\"] = dt_claim[\"date_report\"] + pd.to_timedelta(dt_claim[\"delay_pay\"], unit='D')\n",
    "    dt_claim[\"claim_cost\"] = (dt_claim[\"Price\"] * dt_claim[\"claim_sev\"]).round().astype(int)\n",
    "\n",
    "    dt_claim[\"clm_prefix\"] = dt_claim[\"date_report\"].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "    dt_claim[\"clm_seq\"] = dt_claim.groupby(\"clm_prefix\").cumcount() + 1\n",
    "    dt_claim[\"clm_prefix\"] = dt_claim[\"date_report\"].dt.strftime(\"%Y%m%d\")\n",
    "    dt_claim[\"clm_seq\"] = dt_claim.groupby(\"clm_prefix\").cumcount() + 1\n",
    "\n",
    "        # Use zfill for consistent formatting\n",
    "    dt_claim[\"clm_number\"] = dt_claim[\"clm_prefix\"].astype(str) + dt_claim[\"clm_seq\"].astype(str).str.zfill(4)\n",
    "\n",
    "\n",
    "    # Keep only first claim per policy\n",
    "    dt_claim[\"polclm_seq\"] = dt_claim.groupby(\"pol_number\").cumcount() + 1\n",
    "    dt_claim = dt_claim[dt_claim[\"polclm_seq\"] == 1]\n",
    "\n",
    "    dt_claim = dt_claim[[\n",
    "        \"clm_number\", \"pol_number\", \"claim_type\", \"claim_count\", \"claim_sev\",\n",
    "        \"date_occur\", \"date_report\", \"date_pay\", \"claim_cost\"\n",
    "    ]]\n",
    "\n",
    "    return dt_policy.reset_index(drop=True), dt_claim.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e5bb52-a1dc-4053-80f6-ed7d3dc60645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Sample:\n",
      "     pol_number    date_UW date_lapse Cover  Brand  Model  Price\n",
      "0  201601010001 2016-01-01 2017-01-01     B      1      3    913\n",
      "1  201601010002 2016-01-01 2017-01-01     B      1      3    913\n",
      "2  201601010003 2016-01-01 2017-01-01     B      1      3    913\n",
      "3  201601010004 2016-01-01 2017-01-01     B      1      3    913\n",
      "4  201601010005 2016-01-01 2017-01-01     B      1      3    913\n",
      "\n",
      "Claim Sample:\n",
      "     clm_number    pol_number claim_type  claim_count  claim_sev date_occur  \\\n",
      "0  201805090001  201707030353          B            1   0.639180 2018-04-24   \n",
      "1  201701310001  201610100547          B            1   0.260456 2017-01-31   \n",
      "2  201609250001  201604150398          B            1   0.070113 2016-09-15   \n",
      "3  201705220001  201608220393          B            1   0.150239 2017-05-22   \n",
      "4  201803240001  201706270312          B            1   0.371893 2018-03-19   \n",
      "\n",
      "  date_report   date_pay  claim_cost  \n",
      "0  2018-05-09 2018-06-11         254  \n",
      "1  2017-01-31 2017-03-01         190  \n",
      "2  2016-09-25 2016-10-29          24  \n",
      "3  2017-05-22 2017-06-22         109  \n",
      "4  2018-03-24 2018-04-26         271  \n"
     ]
    }
   ],
   "source": [
    "dt_policy, dt_claim = simulate_central_scenario(1234)\n",
    "\n",
    "print(\"Policy Sample:\")\n",
    "print(dt_policy.head())\n",
    "\n",
    "print(\"\\nClaim Sample:\")\n",
    "print(dt_claim.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c66e6a2-6369-46ab-8632-6e295e2dba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge claims with policy using policy number\n",
    "dt_polclaim = pd.merge(dt_policy, dt_claim, on=\"pol_number\", how=\"left\")\n",
    "\n",
    "# Fill missing values (i.e., policies with no claims)\n",
    "long_future = pd.to_datetime(\"2199-12-31 23:59:59\")\n",
    "dt_polclaim[\"date_occur\"] = dt_polclaim[\"date_occur\"].fillna(long_future)\n",
    "dt_polclaim[\"date_report\"] = dt_polclaim[\"date_report\"].fillna(long_future)\n",
    "dt_polclaim[\"date_pay\"] = dt_polclaim[\"date_pay\"].fillna(long_future)\n",
    "dt_polclaim[\"claim_count\"] = dt_polclaim[\"claim_count\"].fillna(0).astype(int)\n",
    "dt_polclaim[\"claim_sev\"] = dt_polclaim[\"claim_sev\"].fillna(0)\n",
    "dt_polclaim[\"claim_cost\"] = dt_polclaim[\"claim_cost\"].fillna(0).astype(int)\n",
    "\n",
    "# Add exposure days\n",
    "dt_polclaim[\"ExpoDays\"] = ((dt_polclaim[\"date_lapse\"] - dt_polclaim[\"date_UW\"]).dt.days / 365).apply(np.ceil)\n",
    "dt_polclaim = dt_polclaim[dt_polclaim[\"ExpoDays\"] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c15d9fab-bab5-499e-a38a-7e22a736e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 43/43 [00:00<00:00, 123.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from pandas.tseries.offsets import Day\n",
    "\n",
    "# Generate time slices of 30 days\n",
    "lst_date_slice = pd.date_range(\"2016-01-01\", \"2019-06-30\", freq=\"30D\")\n",
    "\n",
    "# Add cumulative payment columns for each slice\n",
    "for t in tqdm(lst_date_slice):\n",
    "    col = f'P_t_{t.strftime(\"%Y%m%d\")}'\n",
    "    dt_polclaim[col] = np.where(dt_polclaim[\"date_pay\"] <= t, dt_polclaim[\"claim_cost\"], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "254d9607-fecf-4ca5-b00c-c75c4351665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of dt_policy:\n",
      "     pol_number    date_UW date_lapse Cover  Brand  Model  Price\n",
      "0  201601010001 2016-01-01 2017-01-01     B      1      3    913\n",
      "1  201601010002 2016-01-01 2017-01-01     B      1      3    913\n",
      "2  201601010003 2016-01-01 2017-01-01     B      1      3    913\n",
      "3  201601010004 2016-01-01 2017-01-01     B      1      3    913\n",
      "4  201601010005 2016-01-01 2017-01-01     B      1      3    913\n"
     ]
    }
   ],
   "source": [
    "# View top rows\n",
    "print(\"Preview of dt_policy:\")\n",
    "print(dt_policy.head())\n",
    "\n",
    "# Save to CSV\n",
    "#dt_policy.to_csv(\"dt_policy.csv\", index=False)\n",
    "#print(\"Saved dt_policy.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d20d6250-934f-4691-8942-2c2435607bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of dt_claim:\n",
      "     clm_number    pol_number claim_type  claim_count  claim_sev date_occur  \\\n",
      "0  201805090001  201707030353          B            1   0.639180 2018-04-24   \n",
      "1  201701310001  201610100547          B            1   0.260456 2017-01-31   \n",
      "2  201609250001  201604150398          B            1   0.070113 2016-09-15   \n",
      "3  201705220001  201608220393          B            1   0.150239 2017-05-22   \n",
      "4  201803240001  201706270312          B            1   0.371893 2018-03-19   \n",
      "\n",
      "  date_report   date_pay  claim_cost  \n",
      "0  2018-05-09 2018-06-11         254  \n",
      "1  2017-01-31 2017-03-01         190  \n",
      "2  2016-09-25 2016-10-29          24  \n",
      "3  2017-05-22 2017-06-22         109  \n",
      "4  2018-03-24 2018-04-26         271  \n"
     ]
    }
   ],
   "source": [
    "# View top rows\n",
    "print(\"\\nPreview of dt_claim:\")\n",
    "print(dt_claim.head())\n",
    "\n",
    "# Save to CSV\n",
    "#dt_claim.to_csv(\"dt_claim.csv\", index=False)\n",
    "#print(\"Saved dt_claim.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3034f56c-8607-4de8-a93b-e527aaae239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of dt_polclaim (joined + timesliced):\n",
      "     pol_number    date_UW date_lapse Cover  Brand  Model  Price clm_number  \\\n",
      "0  201601010001 2016-01-01 2017-01-01     B      1      3    913        NaN   \n",
      "1  201601010002 2016-01-01 2017-01-01     B      1      3    913        NaN   \n",
      "2  201601010003 2016-01-01 2017-01-01     B      1      3    913        NaN   \n",
      "3  201601010004 2016-01-01 2017-01-01     B      1      3    913        NaN   \n",
      "4  201601010005 2016-01-01 2017-01-01     B      1      3    913        NaN   \n",
      "\n",
      "  claim_type  claim_count  claim_sev          date_occur         date_report  \\\n",
      "0        NaN            0        0.0 2199-12-31 23:59:59 2199-12-31 23:59:59   \n",
      "1        NaN            0        0.0 2199-12-31 23:59:59 2199-12-31 23:59:59   \n",
      "2        NaN            0        0.0 2199-12-31 23:59:59 2199-12-31 23:59:59   \n",
      "3        NaN            0        0.0 2199-12-31 23:59:59 2199-12-31 23:59:59   \n",
      "4        NaN            0        0.0 2199-12-31 23:59:59 2199-12-31 23:59:59   \n",
      "\n",
      "             date_pay  claim_cost  \n",
      "0 2199-12-31 23:59:59           0  \n",
      "1 2199-12-31 23:59:59           0  \n",
      "2 2199-12-31 23:59:59           0  \n",
      "3 2199-12-31 23:59:59           0  \n",
      "4 2199-12-31 23:59:59           0  \n",
      "Saved dt_polclaim.csv\n"
     ]
    }
   ],
   "source": [
    "# View top rows\n",
    "print(\"\\nPreview of dt_polclaim (joined + timesliced):\")\n",
    "print(dt_polclaim.iloc[:, :15].head())  # Show first 15 columns for readability\n",
    "\n",
    "# Save full dataset to CSV\n",
    "#dt_polclaim.to_csv(\"dt_polclaim.csv\", index=False)\n",
    "print(\"Saved dt_polclaim.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
